{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shampoo example from data science mistery"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3D data with one feature and one sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "# be able to save images on server\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    " \n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf = df.drop(0)\n",
    "\treturn df\n",
    " \n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    " \n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    " \n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, yhat):\n",
    "\tnew_row = [x for x in X] + [yhat]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    " \n",
    "# evaluate the model on a dataset, returns RMSE in transformed units\n",
    "def evaluate(model, raw_data, scaled_dataset, scaler, offset, batch_size):\n",
    "\t# separate\n",
    "\tX, y = scaled_dataset[:,0:-1], scaled_dataset[:,-1]\n",
    "\t# reshape\n",
    "\treshaped = X.reshape(len(X), 1, 1)\n",
    "\t# forecast dataset\n",
    "\toutput = model.predict(reshaped, batch_size=batch_size)\n",
    "\t# invert data transforms on forecast\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(output)):\n",
    "\t\tyhat = output[i,0]\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X[i], yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = yhat + raw_data[i]\n",
    "\t\t# store forecast\n",
    "\t\tpredictions.append(yhat)\n",
    "\t# report performance\n",
    "\trmse = sqrt(mean_squared_error(raw_data[1:], predictions))\n",
    "\treturn rmse\n",
    " \n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, test, raw, scaler, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])   #change it to 3D data\n",
    "\t# prepare model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\t# fit model\n",
    "\ttrain_rmse, test_rmse = list(), list()\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\t\t# evaluate model on train data\n",
    "\t\traw_train = raw[-(len(train)+len(test)+1):-len(test)]\n",
    "\t\ttrain_rmse.append(evaluate(model, raw_train, train, scaler, 0, batch_size))\n",
    "\t\tmodel.reset_states()\n",
    "\t\t# evaluate model on test data\n",
    "\t\traw_test = raw[-(len(test)+1):]\n",
    "\t\ttest_rmse.append(evaluate(model, raw_test, test, scaler, 0, batch_size))\n",
    "\t\tmodel.reset_states()\n",
    "\thistory = DataFrame()\n",
    "\thistory['train'], history['test'] = train_rmse, test_rmse\n",
    "\treturn history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "series = read_csv('shapoo.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "\t# transform data to be stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_values = series.values\n",
    "diff_values = difference(raw_values, 1)\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    -120.1\n1      37.2\n2     -63.8\n3      61.0\n4     -11.8\n5      63.3\n6      -7.3\n7     -31.7\n8     -69.9\n9     213.6\n10   -150.6\n11      8.4\n12    -44.8\n13     60.6\n14     63.2\n15    -81.9\n16     95.6\n17    -61.0\n18     77.6\n19    -13.7\n20    131.7\n21   -157.1\n22     77.8\n23     -2.6\n24    100.7\n25   -124.5\n26    123.4\n27    -38.0\n28     36.1\n29    138.1\n30   -167.9\n31    274.4\n32   -206.7\n33    106.0\n34     65.6\ndtype: float64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-120.1,   37.2],\n       [  37.2,  -63.8],\n       [ -63.8,   61. ],\n       [  61. ,  -11.8],\n       [ -11.8,   63.3],\n       [  63.3,   -7.3],\n       [  -7.3,  -31.7],\n       [ -31.7,  -69.9],\n       [ -69.9,  213.6],\n       [ 213.6, -150.6],\n       [-150.6,    8.4],\n       [   8.4,  -44.8],\n       [ -44.8,   60.6],\n       [  60.6,   63.2],\n       [  63.2,  -81.9],\n       [ -81.9,   95.6],\n       [  95.6,  -61. ],\n       [ -61. ,   77.6],\n       [  77.6,  -13.7],\n       [ -13.7,  131.7],\n       [ 131.7, -157.1],\n       [-157.1,   77.8],\n       [  77.8,   -2.6],\n       [  -2.6,  100.7],\n       [ 100.7, -124.5],\n       [-124.5,  123.4],\n       [ 123.4,  -38. ],\n       [ -38. ,   36.1],\n       [  36.1,  138.1],\n       [ 138.1, -167.9],\n       [-167.9,  274.4],\n       [ 274.4, -206.7],\n       [-206.7,  106. ],\n       [ 106. ,   65.6]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test-sets\n",
    "train, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\t# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\t# fit and evaluate model\n",
    "train_trimmed = train_scaled[2:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.496628  ,  0.17669274],\n       [ 0.17669274, -0.21607769],\n       [-0.21607769,  0.1891017 ],\n       [ 0.1891017 , -0.1917993 ],\n       [-0.1917993 , -0.32344214],\n       [-0.32344214, -0.52953871],\n       [-0.52953871,  1.        ],\n       [ 1.        , -0.96493121],\n       [-0.96493121, -0.10709469],\n       [-0.10709469, -0.39411923],\n       [-0.39411923,  0.17453466],\n       [ 0.17453466,  0.18856218],\n       [ 0.18856218, -0.59428109],\n       [-0.59428109,  0.3633666 ],\n       [ 0.3633666 , -0.48152145],\n       [-0.48152145,  0.26625303],\n       [ 0.26625303, -0.22632857],\n       [-0.22632857,  0.55813326],\n       [ 0.55813326, -1.        ],\n       [-1.        ,  0.26733207]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_trimmed[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], 1, X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3D data with one feature and one sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[-0.496628  ]],\n\n       [[ 0.17669274]],\n\n       [[-0.21607769]],\n\n       [[ 0.1891017 ]],\n\n       [[-0.1917993 ]],\n\n       [[-0.32344214]],\n\n       [[-0.52953871]],\n\n       [[ 1.        ]],\n\n       [[-0.96493121]],\n\n       [[-0.10709469]],\n\n       [[-0.39411923]],\n\n       [[ 0.17453466]],\n\n       [[ 0.18856218]],\n\n       [[-0.59428109]],\n\n       [[ 0.3633666 ]],\n\n       [[-0.48152145]],\n\n       [[ 0.26625303]],\n\n       [[-0.22632857]],\n\n       [[ 0.55813326]],\n\n       [[-1.        ]]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.17669274, -0.21607769,  0.1891017 , -0.1917993 , -0.32344214,\n       -0.52953871,  1.        , -0.96493121, -0.10709469, -0.39411923,\n        0.17453466,  0.18856218, -0.59428109,  0.3633666 , -0.48152145,\n        0.26625303, -0.22632857,  0.55813326, -1.        ,  0.26733207])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trimmed[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0) TrainRMSE=91.206313, TestRMSE=135.305723\n1) TrainRMSE=81.388118, TestRMSE=121.823147\n2) TrainRMSE=90.118667, TestRMSE=126.393225\n3) TrainRMSE=87.100322, TestRMSE=129.248256\n4) TrainRMSE=85.779837, TestRMSE=124.358386\n5) TrainRMSE=88.494112, TestRMSE=131.215254\n6) TrainRMSE=99.981369, TestRMSE=144.089385\n7) TrainRMSE=89.551811, TestRMSE=131.877691\n8) TrainRMSE=87.813744, TestRMSE=129.172444\n9) TrainRMSE=89.813615, TestRMSE=132.821290\n"
    }
   ],
   "source": [
    "# config\n",
    "repeats = 10\n",
    "n_batch = 4\n",
    "n_epochs = 10\n",
    "n_neurons = 1\n",
    "\t# run diagnostic tests\n",
    "for i in range(repeats):\n",
    "\thistory = fit_lstm(train_trimmed, test_scaled, raw_values, scaler, n_batch, n_epochs, n_neurons)\n",
    "\tpyplot.plot(history['train'], color='blue')\n",
    "\tpyplot.plot(history['test'], color='orange')\n",
    "\tprint('%d) TrainRMSE=%f, TestRMSE=%f' % (i, history['train'].iloc[-1], history['test'].iloc[-1]))\n",
    "pyplot.savefig('epochs_diagnostic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}