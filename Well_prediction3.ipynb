{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit67420126ac8844db8feb4865fa004feb",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is project is to predict the wellhead pressure and flow pattern within the well\n",
    "\n",
    "![shale well](img/shallwellimg.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('simple_well2.csv')\n",
    "dfnoise=pd.read_csv('simple_well_noise3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnoise.drop(columns='Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FlowPatternGasLiquid6'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.get_dummies(df['FlowPatternGasLiquid6'],prefix='FlowPattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnoise2=pd.get_dummies(dfnoise['FlowPatternGasLiquid6'],prefix='FlowPattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df,df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnoise=pd.concat([dfnoise,dfnoise2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='FlowPatternGasLiquid6', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnoise.drop(columns='FlowPatternGasLiquid6', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnoise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre=df['FINAPRESS']\n",
    "X_pre=df.drop(columns=['FINAPRESS','FINATEMP'], axis=1)\n",
    "X_pre=X_pre.iloc[:,0:4]\n",
    "X_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hol=df['HoldupFractionLiquid6']\n",
    "X_hol=df.drop(columns=['HoldupFractionLiquid6','FINATEMP'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pat=df[['FlowPattern_3','FlowPattern_4']]\n",
    "X_pat=df.drop(columns=['FlowPattern_3','FlowPattern_4','FINATEMP'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_noisepre=dfnoise['FINAPRESS']\n",
    "X_noisepre=dfnoise.drop(columns=['FINAPRESS','FINATEMP'], axis=1)\n",
    "X_noisepre=X_noisepre.iloc[:,0:4]\n",
    "y_noisehol=dfnoise['HoldupFractionLiquid6']\n",
    "X_noisehol=dfnoise.drop(columns=['HoldupFractionLiquid6','FINATEMP'], axis=1)\n",
    "y_noisepat=dfnoise[['FlowPattern_3','FlowPattern_4']]\n",
    "X_noisepat=dfnoise.drop(columns=['FlowPattern_3','FlowPattern_4','FINATEMP'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noisepre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_y_plot(paraa, labela, parab, labelb, parac, labelc, parad, labeld, labelx, title):\n",
    "    def make_patch_spines_invisible(ax):\n",
    "        ax.set_frame_on(True)\n",
    "        ax.patch.set_visible(False)\n",
    "        for sp in ax.spines.values():\n",
    "            sp.set_visible(False)\n",
    "    \n",
    "    fig, host = plt.subplots(figsize=(10, 8))\n",
    "    fig.subplots_adjust(right=1)\n",
    "    \n",
    "    par1 = host.twinx()\n",
    "    par2 = host.twinx()\n",
    "    par3 = host.twinx()\n",
    "\n",
    "    # Offset the right spine of par2.  The ticks and label have already been\n",
    "    # placed on the right by twinx above.\n",
    "    par2.spines[\"right\"].set_position((\"axes\", 1.1))\n",
    "    par3.spines[\"right\"].set_position((\"axes\", 1.2))\n",
    "    # Having been created by twinx, par2 has its frame off, so the line of its\n",
    "    # detached spine is invisible.  First, activate the frame but make the patch\n",
    "    # and spines invisible.\n",
    "    make_patch_spines_invisible(par2)\n",
    "    make_patch_spines_invisible(par3)\n",
    "    # Second, show the right spine.\n",
    "    par2.spines[\"right\"].set_visible(True)\n",
    "    par3.spines[\"right\"].set_visible(True)\n",
    "    \n",
    "    p1, = host.plot(paraa, \"b-\", label=labela)\n",
    "    p2, = par1.plot(parab, \"r-\", label=labelb)\n",
    "    p3, = par2.plot(parac, \"g-\", label=labelc)\n",
    "    p4, = par3.plot(parad, \"black\", label=labeld)\n",
    "    \n",
    "    # host.set_xlim(0, 250)\n",
    "    # host.set_ylim(0, 2.2)\n",
    "    # par1.set_ylim(0, 500)\n",
    "    # par2.set_ylim(1, 5000)\n",
    "    # par3.set_ylim(1, 6000)\n",
    "    \n",
    "    host.set_xlabel(labelx, fontsize=14)\n",
    "    host.set_ylabel(labela, fontsize=14)\n",
    "    par1.set_ylabel(labelb, fontsize=14)\n",
    "    par2.set_ylabel(labelc, fontsize=14)\n",
    "    par3.set_ylabel(labeld, fontsize=14)\n",
    "    \n",
    "    host.yaxis.label.set_color(p1.get_color())\n",
    "    par1.yaxis.label.set_color(p2.get_color())\n",
    "    par2.yaxis.label.set_color(p3.get_color())\n",
    "    par3.yaxis.label.set_color(p4.get_color())\n",
    "    \n",
    "    tkw = dict(size=4, width=1.5)\n",
    "    host.tick_params(axis='y', colors=p1.get_color(), labelsize=12)\n",
    "    par1.tick_params(axis='y', colors=p2.get_color(), labelsize=12)\n",
    "    par2.tick_params(axis='y', colors=p3.get_color(), labelsize=12)\n",
    "    par3.tick_params(axis='y', colors=p4.get_color(), labelsize=12)\n",
    "    host.tick_params(axis='x', labelsize=14)\n",
    "    \n",
    "    lines = [p1, p2, p3, p4]\n",
    "    \n",
    "    host.legend(lines, [l.get_label() for l in lines], fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_y_plot(df['Gas Flow_MMSCFD'], \"Gas\",\n",
    "            df['Oil_bpd'], \"Oil\", \n",
    "            df['Water_bpd'],\"Water\",\n",
    "            df['FWHP_psig'], \"Pressure\",\n",
    "            \"Week\",\n",
    "            \"Bottom Hole Conditions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_y_plot(dfnoise['Gas Flow_MMSCFD'], \"Gas\",\n",
    "            dfnoise['Oil_bpd'], \"Oil\", \n",
    "            dfnoise['Water_bpd'],\"Water\",\n",
    "            dfnoise['FWHP_psig'], \"Pressure\",\n",
    "            \"Week\",\n",
    "            \"Flow and Pressure Conditions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre= preprocessing.StandardScaler().fit(X_pre).transform(X_pre)\n",
    "X_pre[0:5]\n",
    "X_hol= preprocessing.StandardScaler().fit(X_hol).transform(X_hol)\n",
    "X_hol[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noisepre= preprocessing.StandardScaler().fit(X_noisepre).transform(X_noisepre)\n",
    "\n",
    "X_noisehol= preprocessing.StandardScaler().fit(X_noisehol).transform(X_noisehol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0=X_pre[0:182]\n",
    "y_train0=y_pre[0:182]\n",
    "X_test0=X_pre[182:]\n",
    "y_test0=y_pre[182:]\n",
    "# hold up data\n",
    "X_hol_train0=X_hol[0:182]\n",
    "y_hol_train0=y_hol[0:182]\n",
    "X_hol_test0=X_hol[182:]\n",
    "y_hol_test0=y_hol[182:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noisetrain0=X_noisepre[0:182]\n",
    "y_noisetrain0=y_noisepre[0:182]\n",
    "X_noisetest0=X_noisepre[182:]\n",
    "y_noisetest0=y_noisepre[182:]\n",
    "# hold up data\n",
    "X_hol_noisetrain0=X_noisehol[0:182]\n",
    "y_hol_noisetrain0=y_noisehol[0:182]\n",
    "X_hol_noisetest0=X_noisehol[182:]\n",
    "y_hol_noisetest0=y_noisehol[182:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_pre[0:182],y_pre[0:182], test_size=0.05,random_state=21)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *SVM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters for smooth line input\n",
    "svr_rbf = svm.SVR(kernel='rbf', C=3000, gamma=0.0019, epsilon=0.1)\n",
    "svr_lin = svm.SVR(kernel='linear', C=52, gamma=0.1, epsilon=0.1)\n",
    "svr_poly = svm.SVR(kernel='poly',gamma=1, degree=3, epsilon=.1,\n",
    "               coef0=2.1)\n",
    "\n",
    "clf=svr_lin.fit(X_train0, y_train0)\n",
    "print(clf.score(X_test0,y_test0))\n",
    "y_hat=svr_lin.predict(X_test0)\n",
    "\n",
    "# print(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# For an initial search, a logarithmic grid with basis\n",
    "# 10 is often helpful. Using a basis of 2, a finer\n",
    "# tuning can be achieved but at a much higher cost.\n",
    "C_range = 10. ** np.arange(-3, 6)\n",
    "gamma_range = 10. ** np.arange(-5, 4)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "\n",
    "X=X_noisetrain0\n",
    "y=y_noisetrain0\n",
    "\n",
    "grid = GridSearchCV(svm.SVR(kernel='poly'), param_grid=param_grid, refit=True, verbose=3)\n",
    "grid.fit(X, y)\n",
    "print(\"The best classifier is: \", grid.best_estimator_)\n",
    "# plot the scores of the grid\n",
    "# grid_scores_ contains parameter settings and scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_valuations(svr_, Xdata, ydata, nsplit, s1, l1, s2, l2, s3, l3):\n",
    "    \n",
    "    kfold = model_selection.KFold(n_splits=nsplit, random_state=21, shuffle=True)\n",
    "    \n",
    "    scores = [s1, s2, s3]\n",
    "    labels = [l1, l2, l3]\n",
    "    \n",
    "    for ix, score in enumerate(scores):\n",
    "        results = model_selection.cross_val_score(svr_, Xdata, ydata, cv=kfold, scoring=scores[ix])\n",
    "        print(\"SVR\", svr_.kernel,labels[ix],format(results.mean(),'.4f'), format(results.std(),'.4f'))\n",
    "    print('\\n')   \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluate different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrs = [svr_rbf, svr_lin, svr_poly]\n",
    "for i in range(len(svrs)):\n",
    "    cross_valuations(svrs[i],\n",
    "                 X_train0,\n",
    "                 y_train0,\n",
    "                 7,\n",
    "                 \"neg_mean_absolute_error\", \"MAE:\",\n",
    "                 \"neg_root_mean_squared_error\", \"RMSE:\",\n",
    "                 \"r2\", \"R^2:\"\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_svr_plot(svr1, label1, svr2, label2, svr3, label3, trainx, trainy, testx, testy, labelx, labely, ftitle):\n",
    "    # Look at the results\n",
    "    lw = 2\n",
    "    \n",
    "    svrs = [svr1, svr2, svr3]\n",
    "    kernel_label = [label1, label2, label3]\n",
    "    model_color = ['b', 'c', 'g']\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24, 12), sharey=True)\n",
    "    for ix, svr in enumerate(svrs):\n",
    "        y_hat=svr.fit(trainx, trainy).predict(testx)\n",
    "        \n",
    "        MAE=format(metrics.mean_absolute_error(testy, y_hat),'.3f')\n",
    "        MSE=format(metrics.mean_squared_error(testy, y_hat),'.2f')\n",
    "        R2=format(metrics.r2_score(testy, y_hat),'.4f')        \n",
    "        \n",
    "        axes[ix].plot(y_hat, color=model_color[ix], lw=lw,\n",
    "                      label='{} (MAE: {},  R^2: {})'.format(kernel_label[ix], MAE, R2))\n",
    "        axes[ix].plot(testy.reset_index(drop=True), color='red', linestyle=':', lw=3,\n",
    "                      label='Test data')                    \n",
    "        axes[ix].legend(loc='upper center', bbox_to_anchor=(0.5, 1.1),\n",
    "                        ncol=1, fancybox=False, shadow=False, fontsize=14)\n",
    "    fig.text(0.5, 0.04, labelx, ha='center', va='center', fontsize=12)\n",
    "    fig.text(0.06, 0.5, labely, ha='center', va='center', rotation='vertical', fontsize=12)\n",
    "    fig.suptitle(ftitle, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_svr_plot(svr_rbf, \"SVR-RBF\",\n",
    "               svr_lin, \"SVR-Linear\",\n",
    "               svr_poly, \"SVR-Poly\",\n",
    "               X_train0,\n",
    "               y_train0,\n",
    "               X_test0,\n",
    "               y_test0,\n",
    "               \"Week\",\n",
    "               \"Pressure\",\n",
    "               \"Support Vector Regression-Pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramters for noise input\n",
    "svr_rbf = svm.SVR(kernel='rbf', C=100000, gamma=0.1, epsilon=0.001)\n",
    "svr_lin = svm.SVR(kernel='linear', C=150, gamma=0.1, epsilon=0.1)\n",
    "svr_poly = svm.SVR(kernel='poly',gamma=0.2, degree=4, epsilon=0.1,\n",
    "               coef0=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrs = [svr_rbf, svr_lin, svr_poly]\n",
    "for i in range(len(svrs)):\n",
    "    cross_valuations(svrs[i],\n",
    "                 X_train0,\n",
    "                 y_train0,\n",
    "                 7,\n",
    "                 \"neg_mean_absolute_error\", \"MAE:\",\n",
    "                 \"neg_root_mean_squared_error\", \"RMSE:\",\n",
    "                 \"r2\", \"R^2:\"\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_svr_plot(svr_rbf, \"SVR-RBF\",\n",
    "               svr_lin, \"SVR-Linear\",\n",
    "               svr_poly, \"SVR-Poly\",\n",
    "               X_noisetrain0,\n",
    "               y_noisetrain0,\n",
    "               X_noisetest0,\n",
    "               y_noisetest0,\n",
    "               \"Week\",\n",
    "               \"Pressure\",\n",
    "               \"Support Vector Regression-Pressure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict Holdup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hol_svr_rbf = svm.SVR(kernel='rbf', C=10, gamma=0.001, epsilon=0.0001)\n",
    "hol_svr_lin = svm.SVR(kernel='linear', C=0.2, gamma=0.005, epsilon=0.0001)\n",
    "hol_svr_poly = svm.SVR(kernel='poly',gamma=0.01, degree=3, epsilon=.0001,\n",
    "               coef0=0.6)\n",
    "\n",
    "svrs = [hol_svr_rbf, hol_svr_lin, hol_svr_poly]\n",
    "for i in range(len(svrs)):\n",
    "    cross_valuations(svrs[i],\n",
    "                 X_hol_train0,\n",
    "                 y_hol_train0,\n",
    "                 10,\n",
    "                 \"neg_mean_absolute_error\", \"MAE:\",\n",
    "                 \"neg_root_mean_squared_error\", \"RMSE:\",\n",
    "                 \"r2\", \"R^2:\"\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_svr_plot(hol_svr_rbf, \"SVR-RBF\",\n",
    "               hol_svr_lin, \"SVR-Linear\",\n",
    "               hol_svr_poly, \"SVR-Poly\",\n",
    "               X_hol_train0,\n",
    "               y_hol_train0,\n",
    "               X_hol_test0,\n",
    "               y_hol_test0,\n",
    "               \"Week\",\n",
    "               \"Liquid Holdup\",\n",
    "               \"Support Vector Regression-Holdup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hol_svr_rbf = svm.SVR(kernel='rbf', C=90, gamma=0.001, epsilon=0.0001)\n",
    "hol_svr_lin = svm.SVR(kernel='linear', C=0.8, gamma=0.004, epsilon=0.0001)\n",
    "hol_svr_poly = svm.SVR(kernel='poly',gamma=0.01, degree=4, epsilon=.00001,\n",
    "               coef0=0.6)\n",
    "\n",
    "svrs = [hol_svr_rbf, hol_svr_lin, hol_svr_poly]\n",
    "for i in range(len(svrs)):\n",
    "    cross_valuations(svrs[i],\n",
    "                 X_hol_noisetrain0,\n",
    "                 y_hol_noisetrain0,\n",
    "                 10,\n",
    "                 \"neg_mean_absolute_error\", \"MAE:\",\n",
    "                 \"neg_root_mean_squared_error\", \"RMSE:\",\n",
    "                 \"r2\", \"R^2:\"\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_svr_plot(hol_svr_rbf, \"SVR-RBF\",\n",
    "               hol_svr_lin, \"SVR-Linear\",\n",
    "               hol_svr_poly, \"SVR-Poly\",\n",
    "               X_hol_noisetrain0,\n",
    "               y_hol_noisetrain0,\n",
    "               X_hol_noisetest0,\n",
    "               y_hol_noisetest0,\n",
    "               \"Week\",\n",
    "               \"Liquid Holdup\",\n",
    "               \"Support Vector Regression-Holdup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train=X_noisetrain0\n",
    "y_train=y_noisetrain0\n",
    "\n",
    "X_test=X_noisetest0\n",
    "y_test=y_noisetest0\n",
    "\n",
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "gbrt= GradientBoostingRegressor(**params)\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "results = cross_val_score(gbrt, X_train, y_train, cv=kfold)\n",
    "print(\"Cross Val Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "\n",
    "gbrt.fit(X_noisetrain0, y_noisetrain0)\n",
    "y_pred = gbrt.predict(X_noisetest0)\n",
    "\n",
    "MAE=format(metrics.mean_absolute_error(y_noisetest0, y_pred),'.3f')\n",
    "MSE=format(metrics.mean_squared_error(y_noisetest0, y_pred),'.2f')\n",
    "R2=format(metrics.r2_score(y_noisetest0, y_pred),'.4f')       \n",
    "\n",
    "lin_mse = mean_squared_error(y_pred, y_noisetest0)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('RMSE: %.4f' % lin_rmse)\n",
    "print('MAE:', MAE)\n",
    "print('MSE:', MSE)\n",
    "print('R2:',  R2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define comparion plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_plot(ml1, label1, trainx, trainy, testx, testy, labelx, labely, ftitle):\n",
    "    # Look at the results\n",
    "    lw = 2\n",
    "    \n",
    "    fig= plt.figure(figsize=(12, 10))\n",
    "   \n",
    "    y_hat=ml1.fit(trainx, trainy).predict(testx)\n",
    "        \n",
    "    MAE=format(metrics.mean_absolute_error(testy, y_hat),'.3f')\n",
    "    MSE=format(metrics.mean_squared_error(testy, y_hat),'.2f')\n",
    "    R2=format(metrics.r2_score(testy, y_hat),'.4f')        \n",
    "        \n",
    "    plt.plot(y_hat, color='blue', lw=lw,\n",
    "                      label='{} (MAE: {},  R^2: {})'.format(label1, MAE, R2))\n",
    "    plt.plot(testy.reset_index(drop=True), color='red', linestyle=':', lw=3,\n",
    "                      label='Test data')                    \n",
    "    plt.legend(loc='upper center',bbox_to_anchor=(0.5, 1.1),fontsize=12)\n",
    "    plt.xlabel(labelx, fontsize=12)\n",
    "    plt.ylabel(labely, fontsize=12)\n",
    "    fig.suptitle(ftitle, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_plot(gbrt, \"GBRT\",\n",
    "          X_train,\n",
    "          y_train,\n",
    "          X_test,\n",
    "          y_test,\n",
    "          \"Week\",\n",
    "          \"Pressure\",\n",
    "          \"Gradient Boost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 500, 'max_depth': 30, 'random_state': 0,}\n",
    "\n",
    "RFR = RandomForestRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = np.arange(10, 200, 10)\n",
    "scores = []\n",
    "for n in estimators:\n",
    "    RFR.set_params(n_estimators=n)\n",
    "    RFR.fit(X_train, y_train)\n",
    "    scores.append(RFR.score(X_test, y_test))\n",
    "fig= plt.figure(figsize=(8, 6))\n",
    "plt.xlabel(\"n_estimator\",fontsize=12)\n",
    "plt.ylabel(\"score\",fontsize=12)\n",
    "fig.suptitle(\"Effect of n_estimators\", fontsize=16)\n",
    "plt.plot(estimators, scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_plot(RFR, \"RFR\",\n",
    "          X_train,\n",
    "          y_train,\n",
    "          X_test,\n",
    "          y_test,\n",
    "          \"Week\",\n",
    "          \"Pressure\",\n",
    "          \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'colsample_bytree': 0.7587948587257435, 'gamma': 0.022613644455269033, 'learning_rate': 0.1275990992289793, 'max_depth': 5, 'n_estimators': 144, 'subsample': 0.7085396127095583}\n",
    "\n",
    "xgbr = xgb.XGBRegressor(**params)\n",
    "\n",
    "xgbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgbr.predict(X_test)\n",
    "\n",
    "MAE=format(metrics.mean_absolute_error(y_test, y_pred),'.3f')\n",
    "MSE=format(metrics.mean_squared_error(y_test, y_pred),'.2f')\n",
    "R2=format(metrics.r2_score(y_test, y_pred),'.4f')       \n",
    "\n",
    "lin_mse = mean_squared_error(y_pred, y_test)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('RMSE: %.4f' % lin_rmse)\n",
    "print('MAE:', MAE)\n",
    "print('MSE:', MSE)\n",
    "print('R2:',  R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_plot(xgbr, \"XGBoost\",\n",
    "          X_train,\n",
    "          y_train,\n",
    "          X_test,\n",
    "          y_test,\n",
    "          \"Week\",\n",
    "          \"Pressure\",\n",
    "          \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgbr.predict(X_test)\n",
    "mse=mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "params = {\n",
    "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"max_depth\": randint(2, 6), # default 3\n",
    "    \"n_estimators\": randint(100, 150), # default 100\n",
    "    \"subsample\": uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=200, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "report_best_scores(search.cv_results_, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}