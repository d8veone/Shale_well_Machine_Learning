{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit750ca1dc6f8c4a69a34fb4156550fb04",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modified from https://gist.github.com/jkleint/1d878d0401b28b281eb75016ed29f2ee"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Example of using Keras to implement a 1D convolutional neural network (CNN) for timeseries prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_regressor(window_size, filter_length, nb_input_series=1, nb_outputs=1, nb_filter=4):\n",
    "    \"\"\":Return: a Keras Model for predicting the next value in a timeseries given a fixed-size lookback window of previous values.\n",
    "\n",
    "    The model can handle multiple input timeseries (`nb_input_series`) and multiple prediction targets (`nb_outputs`).\n",
    "\n",
    "    :param int window_size: The number of previous timeseries values to use as input features.  Also called lag or lookback.\n",
    "    :param int nb_input_series: The number of input timeseries; 1 for a single timeseries.\n",
    "      The `X` input to ``fit()`` should be an array of shape ``(n_instances, window_size, nb_input_series)``; each instance is\n",
    "      a 2D array of shape ``(window_size, nb_input_series)``.  For example, for `window_size` = 3 and `nb_input_series` = 1 (a\n",
    "      single timeseries), one instance could be ``[[0], [1], [2]]``. See ``make_timeseries_instances()``.\n",
    "    :param int nb_outputs: The output dimension, often equal to the number of inputs.\n",
    "      For each input instance (array with shape ``(window_size, nb_input_series)``), the output is a vector of size `nb_outputs`,\n",
    "      usually the value(s) predicted to come after the last value in that input instance, i.e., the next value\n",
    "      in the sequence. The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``.\n",
    "    :param int filter_length: the size (along the `window_size` dimension) of the sliding window that gets convolved with\n",
    "      each position along each instance. The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed\n",
    "      to the number of input timeseries (its \"width\" being `filter_length`), and it can only slide along the window\n",
    "      dimension.  This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not\n",
    "      meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n",
    "    :param int nb_filter: The number of different filters to learn (roughly, input patterns to recognize).\n",
    "    \"\"\"\n",
    "    model = Sequential((\n",
    "        # The first conv layer learns `nb_filter` filters (aka kernels), each of size ``(filter_length, nb_input_series)``.\n",
    "        # Its output will have shape (None, window_size - filter_length + 1, nb_filter), i.e., for each position in\n",
    "        # the input timeseries, the activation of each filter at that position.\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu', input_shape=(window_size, nb_input_series)),\n",
    "        MaxPooling1D(),     # Downsample the output of convolution by 2X.\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu'),\n",
    "        MaxPooling1D(),\n",
    "        Flatten(),\n",
    "        Dense(nb_outputs, activation='linear'),     # For binary classification, change the activation to 'sigmoid'\n",
    "    ))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    # To perform (binary) classification instead:\n",
    "    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_instances(timeseries, window_size):\n",
    "    \"\"\"Make input features and prediction targets from a `timeseries` for use in machine learning.\n",
    "\n",
    "    :return: A tuple of `(X, y, q)`.  `X` are the inputs to a predictor, a 3D ndarray with shape\n",
    "      ``(timeseries.shape[0] - window_size, window_size, timeseries.shape[1] or 1)``.  For each row of `X`, the\n",
    "      corresponding row of `y` is the next value in the timeseries.  The `q` or query is the last instance, what you would use\n",
    "      to predict a hypothetical next (unprovided) value in the `timeseries`.\n",
    "    :param ndarray timeseries: Either a simple vector, or a matrix of shape ``(timestep, series_num)``, i.e., time is axis 0 (the\n",
    "      row) and the series is axis 1 (the column).\n",
    "    :param int window_size: The number of samples to use as input prediction features (also called the lag or lookback).\n",
    "    \"\"\"\n",
    "    timeseries = np.asarray(timeseries)\n",
    "    assert 0 < window_size < timeseries.shape[0]\n",
    "    X = np.atleast_3d(np.array([timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]))\n",
    "    y = timeseries[window_size:]\n",
    "    q = np.atleast_3d([timeseries[-window_size:]])\n",
    "    return X, y, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_timeseries(timeseries, window_size):\n",
    "    \"\"\"Create a 1D CNN regressor to predict the next value in a `timeseries` using the preceding `window_size` elements\n",
    "    as input features and evaluate its performance.\n",
    "\n",
    "    :param ndarray timeseries: Timeseries data with time increasing down the rows (the leading dimension/axis).\n",
    "    :param int window_size: The number of previous timeseries values to use to predict the next.\n",
    "    \"\"\"\n",
    "    filter_length = 5\n",
    "    nb_filter = 4\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T       # Convert 1D vectors to 2D column vectors\n",
    "\n",
    "    nb_samples, nb_series = timeseries.shape\n",
    "    print('\\n\\nTimeseries ({} samples by {} series):\\n'.format(nb_samples, nb_series), timeseries)\n",
    "    model = make_timeseries_regressor(window_size=window_size, filter_length=filter_length, nb_input_series=nb_series, nb_outputs=nb_series, nb_filter=nb_filter)\n",
    "    print('\\n\\nModel with input size {}, output size {}, {} conv filters of length {}'.format(model.input_shape, model.output_shape, nb_filter, filter_length))\n",
    "    model.summary()\n",
    "\n",
    "    X, y, q = make_timeseries_instances(timeseries, window_size)\n",
    "    print('\\n\\nInput features:', X, '\\n\\nOutput labels:', y, '\\n\\nQuery vector:', q, sep='\\n')\n",
    "    test_size = int(0.01 * nb_samples)           # In real life you'd want to use 0.2 - 0.5\n",
    "    X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]\n",
    "    model.fit(X_train, y_train, nb_epoch=25, batch_size=2, validation_data=(X_test, y_test))\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    print('\\n\\nactual', 'predicted', sep='\\t')\n",
    "    for actual, predicted in zip(y_test, pred.squeeze()):\n",
    "        print(actual.squeeze(), predicted, sep='\\t')\n",
    "    print('next', model.predict(q).squeeze(), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Prepare input data, build model, evaluate.\"\"\"\n",
    "    np.set_printoptions(threshold=25)\n",
    "    ts_length = 1000\n",
    "    window_size = 50\n",
    "\n",
    "    print('\\nSimple single timeseries vector prediction')\n",
    "    timeseries = np.arange(ts_length)                   # The timeseries f(t) = t\n",
    "    evaluate_timeseries(timeseries, window_size)\n",
    "\n",
    "    print('\\nMultiple-input, multiple-output prediction')\n",
    "    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n",
    "    evaluate_timeseries(timeseries, window_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All above functions are exexuted line by line below to check data changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nSimple single timeseries vector prediction\n"
    }
   ],
   "source": [
    "np.set_printoptions(threshold=25)\n",
    "ts_length = 1000\n",
    "window_size = 50\n",
    "\n",
    "print('\\nSimple single timeseries vector prediction')\n",
    "timeseries = np.arange(ts_length)                   # The timeseries f(t) = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([  0,   1,   2, ..., 997, 998, 999])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_length = 5\n",
    "nb_filter = 4\n",
    "timeseries = np.atleast_2d(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  0,   1,   2, ..., 997, 998, 999]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if timeseries.shape[0] == 1:\n",
    "    timeseries = timeseries.T       # Convert 1D vectors to 2D column vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 1)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n\nTimeseries (1000 samples by 1 series):\n [[  0]\n [  1]\n [  2]\n ...\n [997]\n [998]\n [999]]\n"
    }
   ],
   "source": [
    "nb_samples, nb_series = timeseries.shape\n",
    "print('\\n\\nTimeseries ({} samples by {} series):\\n'.format(nb_samples, nb_series), timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n\nModel with input size (None, 50, 1), output size (None, 1), 4 conv filters of length 5\nModel: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_5 (Conv1D)            (None, 46, 4)             24        \n_________________________________________________________________\nmax_pooling1d_5 (MaxPooling1 (None, 23, 4)             0         \n_________________________________________________________________\nconv1d_6 (Conv1D)            (None, 19, 4)             84        \n_________________________________________________________________\nmax_pooling1d_6 (MaxPooling1 (None, 9, 4)              0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 36)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 37        \n=================================================================\nTotal params: 145\nTrainable params: 145\nNon-trainable params: 0\n_________________________________________________________________\nC:\\Users\\xuesong.wang1\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", input_shape=(50, 1), filters=4, kernel_size=5)`\nC:\\Users\\xuesong.wang1\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=4, kernel_size=5)`\n"
    }
   ],
   "source": [
    "model = make_timeseries_regressor(window_size=window_size, filter_length=filter_length, nb_input_series=nb_series, nb_outputs=nb_series, nb_filter=nb_filter)\n",
    "print('\\n\\nModel with input size {}, output size {}, {} conv filters of length {}'.format(model.input_shape, model.output_shape, nb_filter, filter_length))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = np.asarray(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  0],\n       [  1],\n       [  2],\n       ...,\n       [997],\n       [998],\n       [999]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 1)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 < window_size < timeseries.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.atleast_3d(np.array([timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(950, 50, 1)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = timeseries[window_size:]\n",
    "q = np.atleast_3d([timeseries[-window_size:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 50],\n       [ 51],\n       [ 52],\n       ...,\n       [997],\n       [998],\n       [999]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(950, 1)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 50, 1)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[950],\n        [951],\n        [952],\n        ...,\n        [997],\n        [998],\n        [999]]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n\nInput features:\n[[[  0]\n  [  1]\n  [  2]\n  ...\n  [ 47]\n  [ 48]\n  [ 49]]\n\n [[  1]\n  [  2]\n  [  3]\n  ...\n  [ 48]\n  [ 49]\n  [ 50]]\n\n [[  2]\n  [  3]\n  [  4]\n  ...\n  [ 49]\n  [ 50]\n  [ 51]]\n\n ...\n\n [[947]\n  [948]\n  [949]\n  ...\n  [994]\n  [995]\n  [996]]\n\n [[948]\n  [949]\n  [950]\n  ...\n  [995]\n  [996]\n  [997]]\n\n [[949]\n  [950]\n  [951]\n  ...\n  [996]\n  [997]\n  [998]]]\n\n\nOutput labels:\n[[ 50]\n [ 51]\n [ 52]\n ...\n [997]\n [998]\n [999]]\n\n\nQuery vector:\n[[[950]\n  [951]\n  [952]\n  ...\n  [997]\n  [998]\n  [999]]]\nC:\\Users\\xuesong.wang1\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n  after removing the cwd from sys.path.\nTrain on 940 samples, validate on 10 samples\nEpoch 1/25\n940/940 [==============================] - 1s 1ms/step - loss: 35031.8746 - mae: 78.6222 - val_loss: 379.5303 - val_mae: 19.4811\nEpoch 2/25\n940/940 [==============================] - 1s 1ms/step - loss: 141.6836 - mae: 10.0206 - val_loss: 174.6505 - val_mae: 13.2151\nEpoch 3/25\n940/940 [==============================] - 1s 1ms/step - loss: 137.6165 - mae: 9.8113 - val_loss: 138.3917 - val_mae: 11.7635\nEpoch 4/25\n940/940 [==============================] - 1s 1ms/step - loss: 133.0499 - mae: 9.6791 - val_loss: 67.5725 - val_mae: 8.2197\nEpoch 5/25\n940/940 [==============================] - 1s 1ms/step - loss: 118.8196 - mae: 9.1791 - val_loss: 403.3097 - val_mae: 20.0822\nEpoch 6/25\n940/940 [==============================] - 1s 1ms/step - loss: 99.6793 - mae: 8.4586 - val_loss: 114.7413 - val_mae: 10.7115\nEpoch 7/25\n940/940 [==============================] - 1s 1ms/step - loss: 81.4839 - mae: 7.5597 - val_loss: 269.4435 - val_mae: 16.4144\nEpoch 8/25\n940/940 [==============================] - 1s 1ms/step - loss: 48.5759 - mae: 5.8243 - val_loss: 12.3662 - val_mae: 3.5165\nEpoch 9/25\n940/940 [==============================] - 1s 1ms/step - loss: 27.6641 - mae: 4.3291 - val_loss: 20.0203 - val_mae: 4.4744\nEpoch 10/25\n940/940 [==============================] - 1s 1ms/step - loss: 13.3803 - mae: 2.9699 - val_loss: 0.5283 - val_mae: 0.7267\nEpoch 11/25\n940/940 [==============================] - 1s 1ms/step - loss: 6.0897 - mae: 1.9974 - val_loss: 1.1495 - val_mae: 1.0722\nEpoch 12/25\n940/940 [==============================] - 1s 1ms/step - loss: 1.2477 - mae: 0.8977 - val_loss: 5.0313 - val_mae: 2.2430\nEpoch 13/25\n940/940 [==============================] - 1s 1ms/step - loss: 23.4869 - mae: 2.6407 - val_loss: 7.2320 - val_mae: 2.6892\nEpoch 14/25\n940/940 [==============================] - 1s 1ms/step - loss: 90.5464 - mae: 4.9477 - val_loss: 33.6442 - val_mae: 5.7999\nEpoch 15/25\n940/940 [==============================] - 1s 1ms/step - loss: 0.1751 - mae: 0.2316 - val_loss: 0.0100 - val_mae: 0.0998\nEpoch 16/25\n940/940 [==============================] - 1s 1ms/step - loss: 0.0095 - mae: 0.0541 - val_loss: 0.0656 - val_mae: 0.2562\nEpoch 17/25\n940/940 [==============================] - 1s 1ms/step - loss: 0.8767 - mae: 0.4779 - val_loss: 0.7684 - val_mae: 0.8766\nEpoch 18/25\n940/940 [==============================] - 1s 1ms/step - loss: 1.1233 - mae: 0.5774 - val_loss: 10.5653 - val_mae: 3.2504\nEpoch 19/25\n940/940 [==============================] - 1s 1ms/step - loss: 63.5469 - mae: 3.9124 - val_loss: 9.7909 - val_mae: 3.1290\nEpoch 20/25\n940/940 [==============================] - 1s 1ms/step - loss: 3.5013 - mae: 1.1387 - val_loss: 0.0028 - val_mae: 0.0528\nEpoch 21/25\n940/940 [==============================] - 1s 1ms/step - loss: 3.1568 - mae: 1.1426 - val_loss: 2.8815 - val_mae: 1.6975\nEpoch 22/25\n940/940 [==============================] - 1s 1ms/step - loss: 6.2819 - mae: 0.9653 - val_loss: 0.1546 - val_mae: 0.3932\nEpoch 23/25\n940/940 [==============================] - 1s 1ms/step - loss: 6.9833 - mae: 0.9209 - val_loss: 6.4334 - val_mae: 2.5364\nEpoch 24/25\n940/940 [==============================] - 1s 1ms/step - loss: 2.6031 - mae: 1.0300 - val_loss: 0.0059 - val_mae: 0.0767\nEpoch 25/25\n940/940 [==============================] - 1s 1ms/step - loss: 22.3196 - mae: 2.0165 - val_loss: 5.4381 - val_mae: 2.3320\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x187a9de6c48>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\n\\nInput features:', X, '\\n\\nOutput labels:', y, '\\n\\nQuery vector:', q, sep='\\n')\n",
    "test_size = int(0.01 * nb_samples)           # In real life you'd want to use 0.2 - 0.5\n",
    "X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]\n",
    "model.fit(X_train, y_train, nb_epoch=25, batch_size=2, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n\nactual\tpredicted\n990\t992.317\n991\t993.3203\n992\t994.32367\n993\t995.32697\n994\t996.33026\n995\t997.3336\n996\t998.3369\n997\t999.3403\n998\t1000.3437\n999\t1001.3469\nnext\t1002.35034\n"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "print('\\n\\nactual', 'predicted', sep='\\t')\n",
    "for actual, predicted in zip(y_test, pred.squeeze()):\n",
    "    print(actual.squeeze(), predicted, sep='\\t')\n",
    "print('next', model.predict(q).squeeze(), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nMultiple-input, multiple-output prediction\n\n\nTimeseries (1000 samples by 2 series):\n [[   0    0]\n [   1   -1]\n [   2   -2]\n ...\n [ 997 -997]\n [ 998 -998]\n [ 999 -999]]\n\n\nModel with input size (None, 50, 2), output size (None, 2), 4 conv filters of length 5\nModel: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_7 (Conv1D)            (None, 46, 4)             44        \n_________________________________________________________________\nmax_pooling1d_7 (MaxPooling1 (None, 23, 4)             0         \n_________________________________________________________________\nconv1d_8 (Conv1D)            (None, 19, 4)             84        \n_________________________________________________________________\nmax_pooling1d_8 (MaxPooling1 (None, 9, 4)              0         \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 36)                0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 2)                 74        \n=================================================================\nTotal params: 202\nTrainable params: 202\nNon-trainable params: 0\n_________________________________________________________________\n\n\nInput features:\n[[[   0    0]\n  [   1   -1]\n  [   2   -2]\n  ...\n  [  47  -47]\n  [  48  -48]\n  [  49  -49]]\n\n [[   1   -1]\n  [   2   -2]\n  [   3   -3]\n  ...\n  [  48  -48]\n  [  49  -49]\n  [  50  -50]]\n\n [[   2   -2]\n  [   3   -3]\n  [   4   -4]\n  ...\n  [  49  -49]\n  [  50  -50]\n  [  51  -51]]\n\n ...\n\n [[ 947 -947]\n  [ 948 -948]\n  [ 949 -949]\n  ...\n  [ 994 -994]\n  [ 995 -995]\n  [ 996 -996]]\n\n [[ 948 -948]\n  [ 949 -949]\n  [ 950 -950]\n  ...\n  [ 995 -995]\n  [ 996 -996]\n  [ 997 -997]]\n\n [[ 949 -949]\n  [ 950 -950]\n  [ 951 -951]\n  ...\n  [ 996 -996]\n  [ 997 -997]\n  [ 998 -998]]]\n\n\nOutput labels:\n[[  50  -50]\n [  51  -51]\n [  52  -52]\n ...\n [ 997 -997]\n [ 998 -998]\n [ 999 -999]]\n\n\nQuery vector:\n[[[ 950 -950]\n  [ 951 -951]\n  [ 952 -952]\n  ...\n  [ 997 -997]\n  [ 998 -998]\n  [ 999 -999]]]\nC:\\Users\\xuesong.wang1\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", input_shape=(50, 2), filters=4, kernel_size=5)`\nC:\\Users\\xuesong.wang1\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=4, kernel_size=5)`\nC:\\Users\\xuesong.wang1\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\nTrain on 940 samples, validate on 10 samples\nEpoch 1/25\n940/940 [==============================] - 2s 2ms/step - loss: 171777.7229 - mae: 176.7948 - val_loss: 320.0939 - val_mae: 16.7483\nEpoch 2/25\n940/940 [==============================] - 2s 2ms/step - loss: 254.3456 - mae: 12.1846 - val_loss: 193.3664 - val_mae: 11.3081\nEpoch 3/25\n940/940 [==============================] - 1s 1ms/step - loss: 250.9113 - mae: 12.0895 - val_loss: 472.4881 - val_mae: 20.4733\nEpoch 4/25\n940/940 [==============================] - 1s 1ms/step - loss: 249.4188 - mae: 12.1148 - val_loss: 376.6246 - val_mae: 18.6580\nEpoch 5/25\n940/940 [==============================] - 1s 1ms/step - loss: 251.6235 - mae: 12.3287 - val_loss: 702.4608 - val_mae: 25.9877\nEpoch 6/25\n940/940 [==============================] - 1s 1ms/step - loss: 241.8983 - mae: 12.0895 - val_loss: 234.6378 - val_mae: 12.1464\nEpoch 7/25\n940/940 [==============================] - 1s 1ms/step - loss: 232.8260 - mae: 11.8920 - val_loss: 333.8269 - val_mae: 14.7642\nEpoch 8/25\n940/940 [==============================] - 1s 1ms/step - loss: 227.3209 - mae: 11.8258 - val_loss: 124.4878 - val_mae: 9.7327\nEpoch 9/25\n940/940 [==============================] - 1s 1ms/step - loss: 220.2929 - mae: 11.7579 - val_loss: 148.7560 - val_mae: 8.9358\nEpoch 10/25\n940/940 [==============================] - 1s 1ms/step - loss: 203.5223 - mae: 11.2308 - val_loss: 642.3915 - val_mae: 24.7544\nEpoch 11/25\n940/940 [==============================] - 1s 1ms/step - loss: 197.9925 - mae: 11.1498 - val_loss: 15.0896 - val_mae: 3.8668\nEpoch 12/25\n940/940 [==============================] - 1s 1ms/step - loss: 184.4394 - mae: 10.8894 - val_loss: 84.1277 - val_mae: 6.5350\nEpoch 13/25\n940/940 [==============================] - 1s 1ms/step - loss: 174.9978 - mae: 10.5551 - val_loss: 71.4956 - val_mae: 6.6933\nEpoch 14/25\n940/940 [==============================] - 1s 1ms/step - loss: 162.5830 - mae: 10.3597 - val_loss: 121.3458 - val_mae: 8.9153\nEpoch 15/25\n940/940 [==============================] - 1s 1ms/step - loss: 130.9459 - mae: 9.1673 - val_loss: 65.7772 - val_mae: 6.7725\nEpoch 16/25\n940/940 [==============================] - 1s 1ms/step - loss: 132.5332 - mae: 9.3253 - val_loss: 290.1142 - val_mae: 16.9768\nEpoch 17/25\n940/940 [==============================] - 1s 1ms/step - loss: 111.9051 - mae: 8.5708 - val_loss: 24.3455 - val_mae: 4.8458\nEpoch 18/25\n940/940 [==============================] - 1s 1ms/step - loss: 110.6757 - mae: 8.6980 - val_loss: 182.0118 - val_mae: 12.8118\nEpoch 19/25\n940/940 [==============================] - 1s 1ms/step - loss: 82.6659 - mae: 7.3477 - val_loss: 20.7053 - val_mae: 3.5764\nEpoch 20/25\n940/940 [==============================] - 1s 1ms/step - loss: 78.2397 - mae: 7.1828 - val_loss: 87.4041 - val_mae: 9.2084\nEpoch 21/25\n940/940 [==============================] - 1s 1ms/step - loss: 67.5665 - mae: 6.7531 - val_loss: 19.5286 - val_mae: 3.6970\nEpoch 22/25\n940/940 [==============================] - 1s 1ms/step - loss: 74.0015 - mae: 7.1834 - val_loss: 173.0980 - val_mae: 13.0497\nEpoch 23/25\n940/940 [==============================] - 1s 1ms/step - loss: 45.6719 - mae: 5.5621 - val_loss: 104.3721 - val_mae: 9.9426\nEpoch 24/25\n940/940 [==============================] - 1s 1ms/step - loss: 47.3040 - mae: 5.5347 - val_loss: 33.1116 - val_mae: 5.6378\nEpoch 25/25\n940/940 [==============================] - 1s 1ms/step - loss: 43.9959 - mae: 5.4068 - val_loss: 73.1802 - val_mae: 7.5933\n\n\nactual\tpredicted\n[ 990 -990]\t[  993.6055 -1001.4239]\n[ 991 -991]\t[  994.6161 -1002.448 ]\n[ 992 -992]\t[  995.62695 -1003.47205]\n[ 993 -993]\t[  996.6377  -1004.49646]\n[ 994 -994]\t[  997.6484  -1005.52075]\n[ 995 -995]\t[  998.65924 -1006.54474]\n[ 996 -996]\t[  999.6703 -1007.5691]\n[ 997 -997]\t[ 1000.6809  -1008.59326]\n[ 998 -998]\t[ 1001.6917 -1009.6175]\n[ 999 -999]\t[ 1002.7026  -1010.64154]\nnext\t[ 1003.7132 -1011.6658]\n"
    }
   ],
   "source": [
    "print('\\nMultiple-input, multiple-output prediction')\n",
    "timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n",
    "evaluate_timeseries(timeseries, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}